{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate LG3 , LG4 (LG3 + AF filter) : for jsuthusky  ,  KI pathogenic\n",
    "\n",
    "1. LG4: if use AF filter , then add function `def filter_AF`; \n",
    "2. LG3: if not, only see the LG3 pred, then comment the function \n",
    "\n",
    "Method:  \n",
    "* check the number of predictions for benign and pathogenic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nancy/miniconda3/envs/bioinfo/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import MissingIndicator, SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from category_encoders import BinaryEncoder\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predic justhusky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" FIRST of ALL-- user need\"\"\"\n",
    "\n",
    "##### please set files\n",
    "# in\n",
    "# vcfgz_in_file = '/Users/nancy/Desktop/RS_projects/data/03_ML/03_predict_new/01_featureV1/justhusky_gatkcomb_rhocall_norm_af_mt_frqf_cadd_vep_parsed_ranked.vcf.gz'\n",
    "variant_consequences_order = './variant_consequences.txt'\n",
    "\n",
    "# out\n",
    "# pred_out_simple = '/Users/nancy/Desktop/RS_projects/result/04_ML_modify/02_evaluate/01_Clinvar_pred-29feats_CJP5-5_LG.csv'\n",
    "\n",
    "\n",
    "##### load fitted preprocessor and model\n",
    "preprocessor = load('/Users/nancy/Desktop/RS_projects/result/04_ML_modify/01_retrainModel_ClinvarJusthuskyNewpatho/models/02_12feats_ClinJustPatho5-5_preprocessor.joblib') # data preprocessor\n",
    "LG_model = load('/Users/nancy/Desktop/RS_projects/result/04_ML_modify/01_retrainModel_ClinvarJusthuskyNewpatho/models/02_12feats_ClinJustPatho5-5_LG.joblib')         # logistic regression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q0/2p8kfxsn7s73349btf1_g07h0000gp/T/ipykernel_95922/2892436993.py:4: DtypeWarning: Columns (22,23,24,25,26,27,31,37,39,40,41,48,49,50,51,53,55,57,66,90,92,94,95) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv('/Users/nancy/Desktop/RS_projects/result/03_ML/03_predict_new/01_featureV1/01_justhusky_features_noclnsig.csv',sep=';')\n"
     ]
    }
   ],
   "source": [
    "## predict\n",
    "\n",
    "\n",
    "df=pd.read_csv('/Users/nancy/Desktop/RS_projects/result/03_ML/03_predict_new/01_featureV1/01_justhusky_features_noclnsig.csv',sep=';')\n",
    "df['idx'] = df.index  # add index column\n",
    "\n",
    "\"\"\" 2.1 choose featuresV1\"\"\"\n",
    "\n",
    "featureV1 = ['idx','CADD', 'AF_TGP', 'Frq', 'IMPACT','GNOMADAF_popmax', 'Hom', 'ORIGIN',\n",
    "       'SPIDEX', 'SWEGENAF', 'Consequence', 'BIOTYPE', 'SIFT',\n",
    "       'PolyPhen', 'MES-SWA_acceptor_alt', 'MES-SWA_acceptor_diff',\n",
    "       'MES-SWA_donor_alt', 'MES-SWA_donor_diff', 'MaxEntScan_alt',\n",
    "       'MaxEntScan_diff', 'GERP++_RS', 'REVEL_score',\n",
    "       'phastCons100way_vertebrate', 'phyloP100way_vertebrate', 'LoFtool',\n",
    "       'pLI_gene_value', 'SpliceAI_pred_DS_AG', 'SpliceAI_pred_DS_AL',\n",
    "       'SpliceAI_pred_DS_DG', 'SpliceAI_pred_DS_DL']         # remove CLNSIG,   add index: 29+1 total\n",
    "\n",
    "df_1 = df[featureV1]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" 2.2 preprocessing and predict \"\"\"\n",
    "\n",
    "## predict function :\n",
    "def predict_score(X,model,df_ori):\n",
    "    # Use preprocessor and model to predict on new data\n",
    "    X_processed = preprocessor.transform(X)\n",
    "    pred = model.predict(X_processed)\n",
    "    prob = model.predict_proba(X_processed)\n",
    "\n",
    "    # put prediction and score back to dataframe with same index\n",
    "    df_out = pd.DataFrame(data = [pred,prob[:,1]]).T\n",
    "    df_out.columns = ['prediction','score']\n",
    "    df_out['score']=df_out['score'].round(3)\n",
    "    df_out = pd.concat([X['idx'],df_out],axis=1)\n",
    "\n",
    "    #  write model outputs in original df at same index rows\n",
    "    df_copy = df_ori.copy() \n",
    "    df_merged = pd.merge(df_ori,df_out, on='idx')    # get only rows merged when index is same\n",
    "    df_copy.loc[df_copy['idx'].isin(df_merged['idx']),['prediction','score']] = df_merged[['prediction','score']].values  # put cells of merged in original dataframe\n",
    "    lst = ['idx','prediction','score']\n",
    "    return df_copy[lst]\n",
    "\n",
    "# data preprocessing and predicted by models\n",
    "df_lg = predict_score(df_1,LG_model,df)\n",
    "\n",
    "# df_lg.to_csv(pred_out_simple,index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" function: filter prediction by AF > 0.01:\n",
    "if any AF > 0.01 & patho, change patho to benign \n",
    "\n",
    "output: precdiction by model after filtering \"\"\"\n",
    "\n",
    "\n",
    "# function:  to get the maximum non-NaN value in a row\n",
    "def min_nonnan(row):\n",
    "    nonnan_vals = [val for val in row if not np.isnan(val)]\n",
    "    return max(nonnan_vals) if nonnan_vals else np.nan\n",
    "\n",
    "\n",
    "## function: transfer `predicted patho`` with any AF>=0.01, to `benign`\n",
    "def filter_AF(df_extracted_ori,df_pred_out):\n",
    "\n",
    "    af = ['AF_ESP', 'AF_EXAC', 'AF_TGP', 'Frq', 'GNOMADAF_popmax', 'SWEGENAF']\n",
    "    df_af = df_extracted_ori[af]  # Extract all related to AF parameters from the data\n",
    "\n",
    "    df_merge_af = pd.concat([df_pred_out, df_af], axis=1)\n",
    "    df_merge_af['AF_min'] = df_merge_af[af].apply(min_nonnan, axis=1)   # create a new 'AF_min' column\n",
    "\n",
    "    \n",
    "    df_filter = df_merge_af.copy()\n",
    "    df_filter.loc[(df_filter['prediction'] == 1) & (df_filter['AF_min'] >= 0.01), ['prediction']] = 0   # Change 'patho' to 'benign' when min 'AF' is >= 0.01\n",
    "\n",
    "    # Extract the 'prediction' and 'score' columns from the filtered data\n",
    "    df_pred_out_1 = df_filter[['prediction', 'score']]\n",
    "\n",
    "    # Return the value counts of 'prediction'\n",
    "    return df_pred_out_1\n",
    "\n",
    "df_lg = filter_AF(df,df_lg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate   Justhusy - prediction results: for all Justhusky variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    4575006\n",
       "1.0        268\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lg.prediction.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predic KI pathogenic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict\n",
    "\n",
    "\n",
    "df=pd.read_csv('/Users/nancy/Desktop/RS_projects/result/03_ML/03_predict_new/02_featureV2/015_NEWpatho_features_noclnsig.csv',sep=';')\n",
    "df['idx'] = df.index  # add index column\n",
    "\n",
    "\"\"\" 2.1 choose featuresV1\"\"\"\n",
    "\n",
    "featureV1 = ['idx','CADD', 'AF_TGP', 'Frq', 'IMPACT','GNOMADAF_popmax', 'Hom', 'ORIGIN',\n",
    "       'SPIDEX', 'SWEGENAF', 'Consequence', 'BIOTYPE', 'SIFT',\n",
    "       'PolyPhen', 'MES-SWA_acceptor_alt', 'MES-SWA_acceptor_diff',\n",
    "       'MES-SWA_donor_alt', 'MES-SWA_donor_diff', 'MaxEntScan_alt',\n",
    "       'MaxEntScan_diff', 'GERP++_RS', 'REVEL_score',\n",
    "       'phastCons100way_vertebrate', 'phyloP100way_vertebrate', 'LoFtool',\n",
    "       'pLI_gene_value', 'SpliceAI_pred_DS_AG', 'SpliceAI_pred_DS_AL',\n",
    "       'SpliceAI_pred_DS_DG', 'SpliceAI_pred_DS_DL']         # remove CLNSIG,   add index: 29+1 total\n",
    "\n",
    "df_1 = df[featureV1]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" 2.2 preprocessing and predict \"\"\"\n",
    "\n",
    "## predict function :\n",
    "def predict_score(X,model,df_ori):\n",
    "    # Use preprocessor and model to predict on new data\n",
    "    X_processed = preprocessor.transform(X)\n",
    "    pred = model.predict(X_processed)\n",
    "    prob = model.predict_proba(X_processed)\n",
    "\n",
    "    # put prediction and score back to dataframe with same index\n",
    "    df_out = pd.DataFrame(data = [pred,prob[:,1]]).T\n",
    "    df_out.columns = ['prediction','score']\n",
    "    df_out['score']=df_out['score'].round(3)\n",
    "    df_out = pd.concat([X['idx'],df_out],axis=1)\n",
    "\n",
    "    #  write model outputs in original df at same index rows\n",
    "    df_copy = df_ori.copy() \n",
    "    df_merged = pd.merge(df_ori,df_out, on='idx')    # get only rows merged when index is same\n",
    "    df_copy.loc[df_copy['idx'].isin(df_merged['idx']),['prediction','score']] = df_merged[['prediction','score']].values  # put cells of merged in original dataframe\n",
    "    lst = ['idx','prediction','score']\n",
    "    return df_copy[lst]\n",
    "\n",
    "# data preprocessing and predicted by models\n",
    "df_lg_newpatho = predict_score(df_1,LG_model,df)\n",
    "\n",
    "# df_lg.to_csv(pred_out_simple,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filter_AF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_lg_newpatho \u001b[39m=\u001b[39m filter_AF(df,df_lg_newpatho)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filter_AF' is not defined"
     ]
    }
   ],
   "source": [
    "df_lg_newpatho = filter_AF(df,df_lg_newpatho)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate all new patho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    789\n",
       "0.0    188\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lg_newpatho.prediction.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 08:08:27) [Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c02203d1d64a20e095821dadd6770e07e454ea747f2e6a086ab8a4b96e3b68a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
