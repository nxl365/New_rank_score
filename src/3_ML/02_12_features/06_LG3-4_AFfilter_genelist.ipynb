{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check gene list match LG3 , LG4 (LG3 + AF filter) : for jsuthusky  ,  KI pathogenic, and remaining half 50%(justhusky+KI)\n",
    "\n",
    "1. LG4: if use AF filter , then add function `def filter_AF`; \n",
    "2. LG3: if not, only see the LG3 pred, then comment the function \n",
    "\n",
    "Method:  \n",
    "* check if genelist' name match our datasets' Symbol\n",
    "1. for justhusky: check how many prediction pathogenic by LG matched genelists\n",
    "2. for newpatho: just check how many newpatho orignial file matched genelist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nancy/miniconda3/envs/bioinfo/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import MissingIndicator, SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from category_encoders import BinaryEncoder\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. justhusky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" FIRST of ALL-- user need\"\"\"\n",
    "\n",
    "##### please set files\n",
    "# in\n",
    "# vcfgz_in_file = '/Users/nancy/Desktop/RS_projects/data/03_ML/03_predict_new/01_featureV1/justhusky_gatkcomb_rhocall_norm_af_mt_frqf_cadd_vep_parsed_ranked.vcf.gz'\n",
    "variant_consequences_order = './variant_consequences.txt'\n",
    "\n",
    "# out\n",
    "# pred_out_simple = '/Users/nancy/Desktop/RS_projects/result/04_ML_modify/02_evaluate/01_Clinvar_pred-29feats_CJP5-5_LG.csv'\n",
    "\n",
    "\n",
    "##### load fitted preprocessor and model\n",
    "preprocessor = load('/Users/nancy/Desktop/RS_projects/result/04_ML_modify/01_retrainModel_ClinvarJusthuskyNewpatho/models/02_12feats_ClinJustPatho5-5_preprocessor.joblib') # data preprocessor\n",
    "LG_model = load('/Users/nancy/Desktop/RS_projects/result/04_ML_modify/01_retrainModel_ClinvarJusthuskyNewpatho/models/02_12feats_ClinJustPatho5-5_LG.joblib')         # logistic regression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q0/2p8kfxsn7s73349btf1_g07h0000gp/T/ipykernel_97101/2892436993.py:4: DtypeWarning: Columns (22,23,24,25,26,27,31,37,39,40,41,48,49,50,51,53,55,57,66,90,92,94,95) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv('/Users/nancy/Desktop/RS_projects/result/03_ML/03_predict_new/01_featureV1/01_justhusky_features_noclnsig.csv',sep=';')\n"
     ]
    }
   ],
   "source": [
    "## predict\n",
    "\n",
    "\n",
    "df=pd.read_csv('/Users/nancy/Desktop/RS_projects/result/03_ML/03_predict_new/01_featureV1/01_justhusky_features_noclnsig.csv',sep=';')\n",
    "df['idx'] = df.index  # add index column\n",
    "\n",
    "\"\"\" 2.1 choose featuresV1\"\"\"\n",
    "### actually, no need change to 12 features here, since our preprocessor will only transfer and get 12 features as well, so doesn't matter if you change here or not\n",
    "\n",
    "featureV1 = ['idx','CADD', 'AF_TGP', 'Frq', 'IMPACT','GNOMADAF_popmax', 'Hom', 'ORIGIN',\n",
    "       'SPIDEX', 'SWEGENAF', 'Consequence', 'BIOTYPE', 'SIFT',\n",
    "       'PolyPhen', 'MES-SWA_acceptor_alt', 'MES-SWA_acceptor_diff',\n",
    "       'MES-SWA_donor_alt', 'MES-SWA_donor_diff', 'MaxEntScan_alt',\n",
    "       'MaxEntScan_diff', 'GERP++_RS', 'REVEL_score',\n",
    "       'phastCons100way_vertebrate', 'phyloP100way_vertebrate', 'LoFtool',\n",
    "       'pLI_gene_value', 'SpliceAI_pred_DS_AG', 'SpliceAI_pred_DS_AL',\n",
    "       'SpliceAI_pred_DS_DG', 'SpliceAI_pred_DS_DL']         # remove CLNSIG,   add index: 29+1 total\n",
    "\n",
    "df_1 = df[featureV1]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" 2.2 preprocessing and predict \"\"\"\n",
    "\n",
    "## predict function :\n",
    "def predict_score(X,model,df_ori):\n",
    "    # Use preprocessor and model to predict on new data\n",
    "    X_processed = preprocessor.transform(X)\n",
    "    pred = model.predict(X_processed)\n",
    "    prob = model.predict_proba(X_processed)\n",
    "\n",
    "    # put prediction and score back to dataframe with same index\n",
    "    df_out = pd.DataFrame(data = [pred,prob[:,1]]).T\n",
    "    df_out.columns = ['prediction','score']\n",
    "    df_out['score']=df_out['score'].round(3)\n",
    "    df_out = pd.concat([X['idx'],df_out],axis=1)\n",
    "\n",
    "    #  write model outputs in original df at same index rows\n",
    "    df_copy = df_ori.copy() \n",
    "    df_merged = pd.merge(df_ori,df_out, on='idx')    # get only rows merged when index is same\n",
    "    df_copy.loc[df_copy['idx'].isin(df_merged['idx']),['prediction','score']] = df_merged[['prediction','score']].values  # put cells of merged in original dataframe\n",
    "    lst = ['idx','prediction','score']\n",
    "    return df_copy[lst]\n",
    "\n",
    "# data preprocessing and predicted by models\n",
    "df_lg = predict_score(df_1,LG_model,df)\n",
    "\n",
    "# df_lg.to_csv(pred_out_simple,index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" function: filter prediction by AF > 0.01:\n",
    "if any AF > 0.01 & patho, change patho to benign \n",
    "\n",
    "output: precdiction by model after filtering \"\"\"\n",
    "\n",
    "\n",
    "# function:  to get the minimum non-NaN value in a row\n",
    "def min_nonnan(row):\n",
    "    nonnan_vals = [val for val in row if not np.isnan(val)]\n",
    "    return min(nonnan_vals) if nonnan_vals else np.nan\n",
    "\n",
    "\n",
    "## function: transfer `predicted patho`` with any AF>=0.01, to `benign`\n",
    "def filter_AF(df_extracted_ori,df_pred_out):\n",
    "\n",
    "    af = ['AF_ESP', 'AF_EXAC', 'AF_TGP', 'Frq', 'GNOMADAF_popmax', 'SWEGENAF']\n",
    "    df_af = df_extracted_ori[af]  # Extract all related to AF parameters from the data\n",
    "\n",
    "    df_merge_af = pd.concat([df_pred_out, df_af], axis=1)\n",
    "    df_merge_af['AF_min'] = df_merge_af[af].apply(min_nonnan, axis=1)   # create a new 'AF_min' column\n",
    "\n",
    "    \n",
    "    df_filter = df_merge_af.copy()\n",
    "    df_filter.loc[(df_filter['prediction'] == 1) & (df_filter['AF_min'] >= 0.01), ['prediction']] = 0   # Change 'patho' to 'benign' when min 'AF' is >= 0.01\n",
    "\n",
    "    # Extract the 'prediction' and 'score' columns from the filtered data\n",
    "    df_pred_out_1 = df_filter[['prediction', 'score']]\n",
    "\n",
    "    # Return the value counts of 'prediction'\n",
    "    return df_pred_out_1\n",
    "\n",
    "df_lg = filter_AF(df,df_lg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate   Justhusy - prediction results: for all Justhusky variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    4575006\n",
       "1.0        268\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lg.prediction.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>score</th>\n",
       "      <th>SYMBOL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DDX11L1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DDX11L1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DDX11L1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DDX11L1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DDX11L1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4575269</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4575270</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4575271</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4575272</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4575273</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4575274 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         prediction  score   SYMBOL\n",
       "0               0.0    0.0  DDX11L1\n",
       "1               0.0    0.0  DDX11L1\n",
       "2               0.0    0.0  DDX11L1\n",
       "3               0.0    0.0  DDX11L1\n",
       "4               0.0    0.0  DDX11L1\n",
       "...             ...    ...      ...\n",
       "4575269         0.0    0.0      NaN\n",
       "4575270         0.0    0.0      NaN\n",
       "4575271         0.0    0.0      NaN\n",
       "4575272         0.0    0.0      NaN\n",
       "4575273         0.0    0.0      NaN\n",
       "\n",
       "[4575274 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge all dataframes\n",
    "df_merge_just = pd.concat([df_lg,df.SYMBOL],axis=1)\n",
    "df_merge_just "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>score</th>\n",
       "      <th>SYMBOL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4652</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.857</td>\n",
       "      <td>PRDM16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10368</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.818</td>\n",
       "      <td>NPHP4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19763</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950</td>\n",
       "      <td>VPS13D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20341</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.651</td>\n",
       "      <td>PRAMEF11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67833</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815</td>\n",
       "      <td>SLC6A9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4396283</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.957</td>\n",
       "      <td>AC002472.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426131</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.521</td>\n",
       "      <td>NPTXR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4499162</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.741</td>\n",
       "      <td>ASB12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4563194</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.831</td>\n",
       "      <td>HMGB3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4571188</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.670</td>\n",
       "      <td>SLC9B1P1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         prediction  score      SYMBOL\n",
       "4652            1.0  0.857      PRDM16\n",
       "10368           1.0  0.818       NPHP4\n",
       "19763           1.0  0.950      VPS13D\n",
       "20341           1.0  0.651    PRAMEF11\n",
       "67833           1.0  0.815      SLC6A9\n",
       "...             ...    ...         ...\n",
       "4396283         1.0  0.957  AC002472.1\n",
       "4426131         1.0  0.521       NPTXR\n",
       "4499162         1.0  0.741       ASB12\n",
       "4563194         1.0  0.831       HMGB3\n",
       "4571188         1.0  0.670    SLC9B1P1\n",
       "\n",
       "[268 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## only get pred pathogenic\n",
    "df_merge_just_predpatho = df_merge_just .loc[df_merge_just ['prediction'].isin([1])]\n",
    "df_merge_just_predpatho"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## genelist check match:\n",
    "for justhusky healthy person, check how many perdicted pathogenic by LG model, in genelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get 3 gene list: \n",
    "\n",
    "df_INTE = pd.read_csv('/Users/nancy/Desktop/RS_projects/data/03_ML/gene_list/Intellectual_disability_microarray_and_sequencing.tsv',sep='\\t')\n",
    "df_INTE\n",
    "\n",
    "# count how many `entity name`` is same to `gene symbl :\n",
    "count_same = (df_INTE['Entity Name'] == df_INTE['Gene Symbol']).sum()\n",
    "count_same\n",
    "\n",
    "df_INTE = df_INTE['Entity Name']\n",
    "\n",
    "\n",
    "\n",
    "df_PRI = pd.read_csv('/Users/nancy/Desktop/RS_projects/data/03_ML/gene_list/Primary_ciliary_disorders.tsv',sep='\\t')\n",
    "df_PRI\n",
    "\n",
    "# count how many `entity name`` is same to `gene symbl\n",
    "count_same = (df_PRI['Entity Name'] == df_PRI['Gene Symbol']).sum()\n",
    "count_same\n",
    "\n",
    "df_PRI = df_PRI['Entity Name']\n",
    "\n",
    "\n",
    "\n",
    "df_STR = pd.read_csv('/Users/nancy/Desktop/RS_projects/data/03_ML/gene_list/Structural_eye_disease.tsv',sep='\\t')\n",
    "df_STR\n",
    "\n",
    "# count how many `entity name`` is same to `gene symbl\n",
    "count_same = (df_STR['Entity Name'] == df_STR['Gene Symbol']).sum()\n",
    "count_same\n",
    "\n",
    "df_STR = df_STR['Entity Name']\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### counts: match `symbol` in pathogenic prediction to `entity name` in gene list\n",
    "in gene list: most Entity name is same to Gene Symbol, but some Symbol is Nan since the name is region instead of gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Matches:  38\n",
      "the number of unique matching: 37\n"
     ]
    }
   ],
   "source": [
    "## LG  list_INTE :  how many pathogenic prediction's 'Symbol' matched in the gene lists' 'Entity Name'\n",
    "\n",
    "# Merging the dataframes based on the columns 'a' and 'b'\n",
    "match_result_LG_INT = pd.merge(df_merge_just_predpatho, df_INTE, left_on='SYMBOL', right_on='Entity Name', how='inner')\n",
    "\n",
    "# Printing the merge result and count of matches\n",
    "match_result_LG_INT\n",
    "print(\"Number of Matches: \", len(match_result_LG_INT))\n",
    "\n",
    "#### count the unique values in matching:\n",
    "unique_values = match_result_LG_INT['SYMBOL'].unique()\n",
    "print('the number of unique matching:',len(unique_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Matches:  5\n",
      "the number of unique matching: 5\n"
     ]
    }
   ],
   "source": [
    "## LG  df_PRI :  how many pathogenic prediction's 'Symbol' matched in the gene lists' 'Entity Name'\n",
    "\n",
    "# Merging the dataframes based on the columns 'a' and 'b'\n",
    "match_result_LG_PRI = pd.merge(df_merge_just_predpatho, df_PRI, left_on='SYMBOL', right_on='Entity Name', how='inner')\n",
    "\n",
    "# Printing the merge result and count of matches\n",
    "match_result_LG_PRI\n",
    "print(\"Number of Matches: \", len(match_result_LG_PRI))\n",
    "\n",
    "unique_values = match_result_LG_PRI['SYMBOL'].unique()\n",
    "print('the number of unique matching:',len(unique_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Matches:  10\n",
      "the number of unique matching: 10\n"
     ]
    }
   ],
   "source": [
    "## LG  df_STR :  how many pathogenic prediction's 'Symbol' matched in the gene lists' 'Entity Name'\n",
    "\n",
    "# Merging the dataframes based on the columns 'a' and 'b'\n",
    "match_result_LG_STR = pd.merge(df_merge_just_predpatho, df_STR, left_on='SYMBOL', right_on='Entity Name', how='inner')\n",
    "\n",
    "# Printing the merge result and count of matches\n",
    "match_result_LG_STR\n",
    "print(\"Number of Matches: \", len(match_result_LG_STR))\n",
    "\n",
    "unique_values = match_result_LG_STR['SYMBOL'].unique()\n",
    "print('the number of unique matching:',len(unique_values))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. new patho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict\n",
    "\n",
    "\n",
    "df=pd.read_csv('/Users/nancy/Desktop/RS_projects/result/03_ML/03_predict_new/02_featureV2/015_NEWpatho_features_noclnsig.csv',sep=';')\n",
    "df['idx'] = df.index  # add index column\n",
    "\n",
    "\"\"\" 2.1 choose featuresV1\"\"\"\n",
    "\n",
    "featureV1 = ['idx','CADD', 'AF_TGP', 'Frq', 'IMPACT','GNOMADAF_popmax', 'Hom', 'ORIGIN',\n",
    "       'SPIDEX', 'SWEGENAF', 'Consequence', 'BIOTYPE', 'SIFT',\n",
    "       'PolyPhen', 'MES-SWA_acceptor_alt', 'MES-SWA_acceptor_diff',\n",
    "       'MES-SWA_donor_alt', 'MES-SWA_donor_diff', 'MaxEntScan_alt',\n",
    "       'MaxEntScan_diff', 'GERP++_RS', 'REVEL_score',\n",
    "       'phastCons100way_vertebrate', 'phyloP100way_vertebrate', 'LoFtool',\n",
    "       'pLI_gene_value', 'SpliceAI_pred_DS_AG', 'SpliceAI_pred_DS_AL',\n",
    "       'SpliceAI_pred_DS_DG', 'SpliceAI_pred_DS_DL']         # remove CLNSIG,   add index: 29+1 total\n",
    "\n",
    "df_1 = df[featureV1]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" 2.2 preprocessing and predict \"\"\"\n",
    "\n",
    "## predict function :\n",
    "def predict_score(X,model,df_ori):\n",
    "    # Use preprocessor and model to predict on new data\n",
    "    X_processed = preprocessor.transform(X)\n",
    "    pred = model.predict(X_processed)\n",
    "    prob = model.predict_proba(X_processed)\n",
    "\n",
    "    # put prediction and score back to dataframe with same index\n",
    "    df_out = pd.DataFrame(data = [pred,prob[:,1]]).T\n",
    "    df_out.columns = ['prediction','score']\n",
    "    df_out['score']=df_out['score'].round(3)\n",
    "    df_out = pd.concat([X['idx'],df_out],axis=1)\n",
    "\n",
    "    #  write model outputs in original df at same index rows\n",
    "    df_copy = df_ori.copy() \n",
    "    df_merged = pd.merge(df_ori,df_out, on='idx')    # get only rows merged when index is same\n",
    "    df_copy.loc[df_copy['idx'].isin(df_merged['idx']),['prediction','score']] = df_merged[['prediction','score']].values  # put cells of merged in original dataframe\n",
    "    lst = ['idx','prediction','score']\n",
    "    return df_copy[lst]\n",
    "\n",
    "# data preprocessing and predicted by models\n",
    "df_lg_newpatho = predict_score(df_1,LG_model,df)\n",
    "\n",
    "# df_lg.to_csv(pred_out_simple,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lg_newpatho = filter_AF(df,df_lg_newpatho)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate all new patho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>977 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     prediction  score\n",
       "0           1.0  0.717\n",
       "1           0.0  0.367\n",
       "2           0.0  0.053\n",
       "3           0.0  0.116\n",
       "4           1.0  0.972\n",
       "..          ...    ...\n",
       "972         1.0  0.958\n",
       "973         1.0  0.979\n",
       "974         1.0  0.841\n",
       "975         1.0  0.760\n",
       "976         1.0  0.734\n",
       "\n",
       "[977 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lg_newpatho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    789\n",
       "0.0    188\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lg_newpatho.prediction.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## genelist check match: all new patho\n",
    "df are all patho"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check all new patho match in genelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_allsymbol = df.SYMBOL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Matches:  718\n",
      "the number of unique matching: 422\n"
     ]
    }
   ],
   "source": [
    "## all patho  list_INTE :  how many pathogenic prediction's 'Symbol' matched in the gene lists' 'Entity Name'\n",
    "\n",
    "# Merging the dataframes based on the columns 'a' and 'b'\n",
    "match_result_LG_INT = pd.merge(df_allsymbol, df_INTE, left_on='SYMBOL', right_on='Entity Name', how='inner')\n",
    "\n",
    "# Printing the merge result and count of matches\n",
    "match_result_LG_INT\n",
    "print(\"Number of Matches: \", len(match_result_LG_INT))\n",
    "\n",
    "#### count the unique values in matching:\n",
    "unique_values = match_result_LG_INT['SYMBOL'].unique()\n",
    "print('the number of unique matching:',len(unique_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Matches:  31\n",
      "the number of unique matching: 21\n"
     ]
    }
   ],
   "source": [
    "## all patho df_PRI :  how many pathogenic prediction's 'Symbol' matched in the gene lists' 'Entity Name'\n",
    "\n",
    "# Merging the dataframes based on the columns 'a' and 'b'\n",
    "match_result_LG_PRI = pd.merge(df_allsymbol, df_PRI, left_on='SYMBOL', right_on='Entity Name', how='inner')\n",
    "\n",
    "# Printing the merge result and count of matches\n",
    "match_result_LG_PRI\n",
    "print(\"Number of Matches: \", len(match_result_LG_PRI))\n",
    "\n",
    "unique_values = match_result_LG_PRI['SYMBOL'].unique()\n",
    "print('the number of unique matching:',len(unique_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Matches:  123\n",
      "the number of unique matching: 70\n"
     ]
    }
   ],
   "source": [
    "## all patho  df_STR :  how many pathogenic prediction's 'Symbol' matched in the gene lists' 'Entity Name'\n",
    "\n",
    "# Merging the dataframes based on the columns 'a' and 'b'\n",
    "match_result_LG_STR = pd.merge(df_allsymbol, df_STR, left_on='SYMBOL', right_on='Entity Name', how='inner')\n",
    "\n",
    "# Printing the merge result and count of matches\n",
    "match_result_LG_STR\n",
    "print(\"Number of Matches: \", len(match_result_LG_STR))\n",
    "\n",
    "unique_values = match_result_LG_STR['SYMBOL'].unique()\n",
    "print('the number of unique matching:',len(unique_values))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. half (just + newpatho)  test data:\n",
    "forget to add AF filter, not matter ,just see for fun "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q0/2p8kfxsn7s73349btf1_g07h0000gp/T/ipykernel_97101/262486184.py:3: DtypeWarning: Columns (22,24,25,26,27,31,48,49,50,51,66,92,94,95) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_half_just = pd.read_csv('/Users/nancy/Desktop/RS_projects/data/04_ML_modify/01_retrainModel_ClinvarJusthuskyNewpatho/01_test_half_justhusky.csv')\n"
     ]
    }
   ],
   "source": [
    "## get half just + newpatho test data including rankscore:\n",
    "\n",
    "test_half_just = pd.read_csv('/Users/nancy/Desktop/RS_projects/data/04_ML_modify/01_retrainModel_ClinvarJusthuskyNewpatho/01_test_half_justhusky.csv')\n",
    "test_half_newpatho = pd.read_csv('/Users/nancy/Desktop/RS_projects/data/04_ML_modify/01_retrainModel_ClinvarJusthuskyNewpatho/01_test_half_newpatho.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get half just + newpatho test data including rankscore:\n",
    "\n",
    "merge_test_half_addrankscore = pd.read_csv('/Users/nancy/Desktop/RS_projects/result/04_ML_modify/01_retrainModel_ClinvarJusthuskyNewpatho/01_extract_oldRankscore_29feats_testhalf_JustNewpatho.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ##  2. Data preprocessing and prediction ## \"\"\"\n",
    "\n",
    "\n",
    "\"\"\" 2.1 choose featuresV1\"\"\"\n",
    "\n",
    "merge_test_half_addrankscore['idx'] = merge_test_half_addrankscore.index  # add index column\n",
    "\n",
    "\n",
    "featureV1 = ['idx',\n",
    "'CADD',\n",
    "'Frq',\n",
    "'GNOMADAF_popmax',\n",
    "'Consequence',\n",
    "'BIOTYPE',\n",
    "'PolyPhen',\n",
    "'REVEL_score',\n",
    "'pLI_gene_value',\n",
    "'SpliceAI_pred_DS_AG',\n",
    "'SpliceAI_pred_DS_AL',\n",
    "'SpliceAI_pred_DS_DG',\n",
    "'SpliceAI_pred_DS_DL']         # 12\n",
    "\n",
    "\n",
    "df_1 = merge_test_half_addrankscore[featureV1]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" 2.2 preprocessing and predict \"\"\"\n",
    "\n",
    "## predict function :\n",
    "def predict_score(X,model,df_ori):\n",
    "    # Use preprocessor and model to predict on new data\n",
    "    X_processed = preprocessor.transform(X)\n",
    "    pred = model.predict(X_processed)\n",
    "    prob = model.predict_proba(X_processed)\n",
    "\n",
    "    # put prediction and score back to dataframe with same index\n",
    "    df_out = pd.DataFrame(data = [pred,prob[:,1]]).T\n",
    "    df_out.columns = ['prediction','score']\n",
    "    df_out['score']=df_out['score'].round(3)\n",
    "    df_out = pd.concat([X['idx'],df_out],axis=1)\n",
    "\n",
    "    #  write model outputs in original df at same index rows\n",
    "    df_copy = df_ori.copy() \n",
    "    df_merged = pd.merge(df_ori,df_out, on='idx')    # get only rows merged when index is same\n",
    "    df_copy.loc[df_copy['idx'].isin(df_merged['idx']),['prediction','score']] = df_merged[['prediction','score']].values  # put cells of merged in original dataframe\n",
    "    lst = ['idx','prediction','score']\n",
    "    return df_copy[lst]\n",
    "\n",
    "# data preprocessing and predicted by models\n",
    "df_lg = predict_score(df_1,LG_model,merge_test_half_addrankscore)\n",
    "\n",
    "\n",
    "# df_lg.to_csv(pred_out_simple,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>prediction</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288121</th>\n",
       "      <td>2288121</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288122</th>\n",
       "      <td>2288122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288123</th>\n",
       "      <td>2288123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288124</th>\n",
       "      <td>2288124</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288125</th>\n",
       "      <td>2288125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2288126 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             idx  prediction  score\n",
       "0              0         0.0  0.000\n",
       "1              1         0.0  0.000\n",
       "2              2         0.0  0.000\n",
       "3              3         0.0  0.000\n",
       "4              4         0.0  0.000\n",
       "...          ...         ...    ...\n",
       "2288121  2288121         1.0  0.992\n",
       "2288122  2288122         1.0  0.993\n",
       "2288123  2288123         1.0  0.841\n",
       "2288124  2288124         1.0  0.760\n",
       "2288125  2288125         1.0  0.734\n",
       "\n",
       "[2288126 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge: pred + symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: order -- just up, newpatho down\n",
    "\n",
    "df_half_merge_symble= pd.concat((test_half_just.SYMBOL,test_half_newpatho.SYMBOL),axis = 0)\n",
    "df_half_merge_symble = df_half_merge_symble.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>score</th>\n",
       "      <th>SYMBOL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>DDX11L1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>DDX11L1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>DDX11L1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>DDX11L1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>DDX11L1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288121</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992</td>\n",
       "      <td>MECP2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288122</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993</td>\n",
       "      <td>MECP2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288123</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.841</td>\n",
       "      <td>FLNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288124</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.760</td>\n",
       "      <td>ATP6AP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288125</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.734</td>\n",
       "      <td>G6PD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2288126 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         prediction  score   SYMBOL\n",
       "0               0.0  0.000  DDX11L1\n",
       "1               0.0  0.000  DDX11L1\n",
       "2               0.0  0.000  DDX11L1\n",
       "3               0.0  0.000  DDX11L1\n",
       "4               0.0  0.000  DDX11L1\n",
       "...             ...    ...      ...\n",
       "2288121         1.0  0.992    MECP2\n",
       "2288122         1.0  0.993    MECP2\n",
       "2288123         1.0  0.841     FLNA\n",
       "2288124         1.0  0.760  ATP6AP1\n",
       "2288125         1.0  0.734     G6PD\n",
       "\n",
       "[2288126 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_half_merge= pd.concat((df_lg,df_half_merge_symble),axis = 1)\n",
    "df_half_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    2287583\n",
       "1.0        543\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_half_merge.prediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>prediction</th>\n",
       "      <th>score</th>\n",
       "      <th>SYMBOL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>2283</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.857</td>\n",
       "      <td>PRDM16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34043</th>\n",
       "      <td>34043</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815</td>\n",
       "      <td>SLC6A9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71545</th>\n",
       "      <td>71545</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>RP5-898J17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97231</th>\n",
       "      <td>97231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.862</td>\n",
       "      <td>ANP32E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98734</th>\n",
       "      <td>98734</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.886</td>\n",
       "      <td>FLG2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288121</th>\n",
       "      <td>2288121</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992</td>\n",
       "      <td>MECP2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288122</th>\n",
       "      <td>2288122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993</td>\n",
       "      <td>MECP2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288123</th>\n",
       "      <td>2288123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.841</td>\n",
       "      <td>FLNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288124</th>\n",
       "      <td>2288124</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.760</td>\n",
       "      <td>ATP6AP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288125</th>\n",
       "      <td>2288125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.734</td>\n",
       "      <td>G6PD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>543 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             idx  prediction  score        SYMBOL\n",
       "2283        2283         1.0  0.857        PRDM16\n",
       "34043      34043         1.0  0.815        SLC6A9\n",
       "71545      71545         1.0  0.999  RP5-898J17.1\n",
       "97231      97231         1.0  0.862        ANP32E\n",
       "98734      98734         1.0  0.886          FLG2\n",
       "...          ...         ...    ...           ...\n",
       "2288121  2288121         1.0  0.992         MECP2\n",
       "2288122  2288122         1.0  0.993         MECP2\n",
       "2288123  2288123         1.0  0.841          FLNA\n",
       "2288124  2288124         1.0  0.760       ATP6AP1\n",
       "2288125  2288125         1.0  0.734          G6PD\n",
       "\n",
       "[543 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## only get pred pathogenic\n",
    "df_merge_half_predpatho = df_half_merge.loc[df_half_merge ['prediction'].isin([1])]\n",
    "df_merge_half_predpatho"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check the patho prediction by LG model , how many match genelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Matches:  312\n",
      "the number of unique matching: 226\n"
     ]
    }
   ],
   "source": [
    "## LG  list_INTE :  how many pathogenic prediction's 'Symbol' matched in the gene lists' 'Entity Name'\n",
    "\n",
    "# Merging the dataframes based on the columns 'a' and 'b'\n",
    "match_result_LG_INT = pd.merge(df_merge_half_predpatho, df_INTE, left_on='SYMBOL', right_on='Entity Name', how='inner')\n",
    "\n",
    "# Printing the merge result and count of matches\n",
    "match_result_LG_INT\n",
    "print(\"Number of Matches: \", len(match_result_LG_INT))\n",
    "\n",
    "#### count the unique values in matching:\n",
    "unique_values = match_result_LG_INT['SYMBOL'].unique()\n",
    "print('the number of unique matching:',len(unique_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Matches:  11\n",
      "the number of unique matching: 8\n"
     ]
    }
   ],
   "source": [
    "## LG  df_PRI :  how many pathogenic prediction's 'Symbol' matched in the gene lists' 'Entity Name'\n",
    "\n",
    "# Merging the dataframes based on the columns 'a' and 'b'\n",
    "match_result_LG_PRI = pd.merge(df_merge_half_predpatho, df_PRI, left_on='SYMBOL', right_on='Entity Name', how='inner')\n",
    "\n",
    "# Printing the merge result and count of matches\n",
    "match_result_LG_PRI\n",
    "print(\"Number of Matches: \", len(match_result_LG_PRI))\n",
    "\n",
    "unique_values = match_result_LG_PRI['SYMBOL'].unique()\n",
    "print('the number of unique matching:',len(unique_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Matches:  58\n",
      "the number of unique matching: 37\n"
     ]
    }
   ],
   "source": [
    "## LG  df_STR :  how many pathogenic prediction's 'Symbol' matched in the gene lists' 'Entity Name'\n",
    "\n",
    "# Merging the dataframes based on the columns 'a' and 'b'\n",
    "match_result_LG_STR = pd.merge(df_merge_half_predpatho, df_STR, left_on='SYMBOL', right_on='Entity Name', how='inner')\n",
    "\n",
    "# Printing the merge result and count of matches\n",
    "match_result_LG_STR\n",
    "print(\"Number of Matches: \", len(match_result_LG_STR))\n",
    "\n",
    "unique_values = match_result_LG_STR['SYMBOL'].unique()\n",
    "print('the number of unique matching:',len(unique_values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 08:08:27) [Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c02203d1d64a20e095821dadd6770e07e454ea747f2e6a086ab8a4b96e3b68a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
