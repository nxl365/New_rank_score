{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SFS (SequentialFeatureSelector) to chose features subsets: \n",
    "LG trained on imbalanced ClinVar with 29 features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "from joblib import dump, load\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS    #  pip install mlxtend  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_112/2458230075.py:1: DtypeWarning: Columns (32,49,50,51,54,56,58,92) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('./01_ALLfeatures_extracted_addCLNSIG.csv',sep=';',index_col=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLNSIG</th>\n",
       "      <th>CADD</th>\n",
       "      <th>AF_ESP</th>\n",
       "      <th>AF_EXAC</th>\n",
       "      <th>AF_TGP</th>\n",
       "      <th>Frq</th>\n",
       "      <th>GNOMADAF</th>\n",
       "      <th>GNOMADAF_popmax</th>\n",
       "      <th>Hom</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>...</th>\n",
       "      <th>SpliceAI_pred_DP_AG</th>\n",
       "      <th>SpliceAI_pred_DP_AL</th>\n",
       "      <th>SpliceAI_pred_DP_DG</th>\n",
       "      <th>SpliceAI_pred_DP_DL</th>\n",
       "      <th>SpliceAI_pred_DS_AG</th>\n",
       "      <th>SpliceAI_pred_DS_AL</th>\n",
       "      <th>SpliceAI_pred_DS_DG</th>\n",
       "      <th>SpliceAI_pred_DS_DL</th>\n",
       "      <th>SpliceAI_pred_SYMBOL</th>\n",
       "      <th>genomic_superdups_frac_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uncertain_significance</td>\n",
       "      <td>26.600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>SAMD11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Likely_benign</td>\n",
       "      <td>13.420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>SAMD11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Likely_benign</td>\n",
       "      <td>31.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00056</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-47.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>SAMD11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Uncertain_significance</td>\n",
       "      <td>28.200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-47.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>SAMD11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Likely_benign</td>\n",
       "      <td>11.380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>SAMD11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468907</th>\n",
       "      <td>Benign</td>\n",
       "      <td>7.587</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>USP9Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468908</th>\n",
       "      <td>Uncertain_significance</td>\n",
       "      <td>23.800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468909</th>\n",
       "      <td>Benign</td>\n",
       "      <td>11.200</td>\n",
       "      <td>0.00614</td>\n",
       "      <td>0.00589</td>\n",
       "      <td>0.00243</td>\n",
       "      <td>0.00671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468910</th>\n",
       "      <td>Uncertain_significance</td>\n",
       "      <td>21.600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468911</th>\n",
       "      <td>Likely_benign</td>\n",
       "      <td>5.338</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1468912 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         CLNSIG    CADD   AF_ESP  AF_EXAC   AF_TGP      Frq  \\\n",
       "0        Uncertain_significance  26.600      NaN      NaN      NaN      NaN   \n",
       "1                 Likely_benign  13.420      NaN      NaN      NaN      NaN   \n",
       "2                 Likely_benign  31.000      NaN      NaN      NaN  0.00056   \n",
       "3        Uncertain_significance  28.200      NaN      NaN      NaN      NaN   \n",
       "4                 Likely_benign  11.380      NaN      NaN      NaN      NaN   \n",
       "...                         ...     ...      ...      ...      ...      ...   \n",
       "1468907                  Benign   7.587      NaN      NaN      NaN  0.00070   \n",
       "1468908  Uncertain_significance  23.800      NaN      NaN      NaN      NaN   \n",
       "1468909                  Benign  11.200  0.00614  0.00589  0.00243  0.00671   \n",
       "1468910  Uncertain_significance  21.600      NaN      NaN      NaN      NaN   \n",
       "1468911           Likely_benign   5.338      NaN  0.00000      NaN  0.02530   \n",
       "\n",
       "         GNOMADAF  GNOMADAF_popmax   Hom  ORIGIN  ...  SpliceAI_pred_DP_AG  \\\n",
       "0             NaN              NaN   NaN     1.0  ...                -30.0   \n",
       "1             NaN              NaN   NaN     1.0  ...                  7.0   \n",
       "2        0.000414         0.000195   NaN     1.0  ...                 41.0   \n",
       "3             NaN              NaN   NaN     1.0  ...                 10.0   \n",
       "4             NaN              NaN   NaN     1.0  ...                -35.0   \n",
       "...           ...              ...   ...     ...  ...                  ...   \n",
       "1468907       NaN              NaN   5.0     1.0  ...                 25.0   \n",
       "1468908       NaN              NaN   NaN    32.0  ...                  NaN   \n",
       "1468909       NaN              NaN  48.0     1.0  ...                  NaN   \n",
       "1468910       NaN              NaN   NaN     1.0  ...                  NaN   \n",
       "1468911       NaN              NaN  29.0     1.0  ...                  NaN   \n",
       "\n",
       "         SpliceAI_pred_DP_AL SpliceAI_pred_DP_DG SpliceAI_pred_DP_DL  \\\n",
       "0                       11.0                10.0               -30.0   \n",
       "1                      -34.0                 6.0                42.0   \n",
       "2                      -47.0                -7.0                44.0   \n",
       "3                      -47.0                34.0               -14.0   \n",
       "4                      -50.0                12.0                24.0   \n",
       "...                      ...                 ...                 ...   \n",
       "1468907                 35.0                 0.0                16.0   \n",
       "1468908                  NaN                 NaN                 NaN   \n",
       "1468909                  NaN                 NaN                 NaN   \n",
       "1468910                  NaN                 NaN                 NaN   \n",
       "1468911                  NaN                 NaN                 NaN   \n",
       "\n",
       "        SpliceAI_pred_DS_AG SpliceAI_pred_DS_AL SpliceAI_pred_DS_DG  \\\n",
       "0                      0.01                0.00                0.09   \n",
       "1                      0.00                0.02                0.03   \n",
       "2                      0.00                0.01                0.06   \n",
       "3                      0.00                0.00                0.03   \n",
       "4                      0.00                0.00                0.01   \n",
       "...                     ...                 ...                 ...   \n",
       "1468907                0.00                0.00                0.00   \n",
       "1468908                 NaN                 NaN                 NaN   \n",
       "1468909                 NaN                 NaN                 NaN   \n",
       "1468910                 NaN                 NaN                 NaN   \n",
       "1468911                 NaN                 NaN                 NaN   \n",
       "\n",
       "        SpliceAI_pred_DS_DL SpliceAI_pred_SYMBOL genomic_superdups_frac_match  \n",
       "0                      0.00               SAMD11                          NaN  \n",
       "1                      0.00               SAMD11                          NaN  \n",
       "2                      0.00               SAMD11                          NaN  \n",
       "3                      0.02               SAMD11                          NaN  \n",
       "4                      0.00               SAMD11                          NaN  \n",
       "...                     ...                  ...                          ...  \n",
       "1468907                0.00                USP9Y                          NaN  \n",
       "1468908                 NaN                  NaN                          NaN  \n",
       "1468909                 NaN                  NaN                          NaN  \n",
       "1468910                 NaN                  NaN                          NaN  \n",
       "1468911                 NaN                  NaN                          NaN  \n",
       "\n",
       "[1468912 rows x 93 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./01_ALLfeatures_extracted_addCLNSIG.csv',sep=';',index_col=False)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 1. choose featuresV1\"\"\"\n",
    "\n",
    "featureV1 = ['CLNSIG','CADD', 'AF_TGP', 'Frq', 'IMPACT','GNOMADAF_popmax', 'Hom', 'ORIGIN',\n",
    "       'SPIDEX', 'SWEGENAF', 'Consequence', 'BIOTYPE', 'SIFT',\n",
    "       'PolyPhen', 'MES-SWA_acceptor_alt', 'MES-SWA_acceptor_diff',\n",
    "       'MES-SWA_donor_alt', 'MES-SWA_donor_diff', 'MaxEntScan_alt',\n",
    "       'MaxEntScan_diff', 'GERP++_RS', 'REVEL_score',\n",
    "       'phastCons100way_vertebrate', 'phyloP100way_vertebrate', 'LoFtool',\n",
    "       'pLI_gene_value', 'SpliceAI_pred_DS_AG', 'SpliceAI_pred_DS_AL',\n",
    "       'SpliceAI_pred_DS_DG', 'SpliceAI_pred_DS_DL']         # keep CLNSIG,\n",
    "\n",
    "df_1 = df[featureV1]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" 2. only remove missing target \"\"\"\n",
    "# for some features with fewer missing\n",
    "# drop_nan_features = ['CLNSIG','CADD','Consequence','IMPACT','BIOTYPE','MES-SWA_acceptor_alt','MES-SWA_acceptor_diff',\n",
    "# 'MES-SWA_donor_alt','MES-SWA_donor_diff','pLI_gene_value']\n",
    "\n",
    "drop_nan_features = ['CLNSIG']\n",
    "df_1 = df_1.dropna(subset=drop_nan_features)\n",
    "\n",
    "\n",
    "\"\"\" 3. deal with target feature \"\"\"\n",
    "# \"\"\"  CLNSIG: tansfer to 4 classes__ benign,pathogenic,uncertain,others\n",
    "# NOTE:\n",
    "# (only count name before |)   explanation-- https://www.ncbi.nlm.nih.gov/clinvar/docs/clinsig/#clinsig_scv\n",
    "\n",
    "# 1. pathogenic: Pathogenic, Pathogenic/Likely_pathogenic, Likely_pathogenic\n",
    "# 2. benign: Likely_benign, Benign, Benign/Likely_benign\n",
    "# 3. uncertain: Uncertain_significance, \n",
    "# 4. others: Uncertain_risk_allele, risk_factor, protective, other, not_provided, Likely_risk_allele, drug_response, Conflicting_interpretations_of_pathogenicity, confers_sensitivity, associatio, Affects\n",
    "\n",
    "df_1 = df_1.copy()\n",
    "df_1['CLNSIG'] = df_1['CLNSIG'].replace(['Uncertain_significance|_risk_factor', 'Uncertain_significance|_other', 'Uncertain_significance|_drug_response','Uncertain_significance|_association','Uncertain_significance|_Affects','Uncertain_significance'], 'uncertain')\n",
    "df_1['CLNSIG'] = df_1['CLNSIG'].replace(['Pathogenic|_risk_factor','Pathogenic|_protective','Pathogenic|_other','Pathogenic|_drug_response|_other','Pathogenic|_drug_response','Pathogenic|_confers_sensitivity','Pathogenic|_association','Pathogenic|_Affects','Pathogenic/Likely_risk_allele','Pathogenic/Likely_pathogenic|_risk_factor','Pathogenic/Likely_pathogenic|_other','Pathogenic/Likely_pathogenic|_drug_response','Pathogenic/Likely_pathogenic','Pathogenic','Likely_pathogenic|_risk_factor','Likely_pathogenic|_other','Likely_pathogenic|_drug_response','Likely_pathogenic|_association','Likely_pathogenic|_Affects','Likely_pathogenic,_low_penetrance','Likely_pathogenic'], 'pathogenic')\n",
    "df_1['CLNSIG'] = df_1['CLNSIG'].replace(['Likely_benign|_risk_factor','Likely_benign|_other','Likely_benign|_drug_response|_other','Likely_benign','Benign|_risk_factor','Benign|_protective','Benign|_other','Benign|_drug_response','Benign|_confers_sensitivity','Benign|_association|_confers_sensitivity','Benign|_association','Benign/Likely_benign|_risk_factor','Benign/Likely_benign|_other|_risk_factor','Benign/Likely_benign|_other','Benign/Likely_benign|_drug_response|_other','Benign/Likely_benign|_drug_response','Benign/Likely_benign|_association','Benign/Likely_benign','Benign'], 'benign')\n",
    "df_1['CLNSIG'] = df_1['CLNSIG'].replace(['Uncertain_risk_allele|_risk_factor','Uncertain_risk_allele','risk_factor','protective','protective|_risk_factor','other', 'not_provided','Likely_risk_allele','drug_response|_risk_factor','drug_response|_other','drug_response','Conflicting_interpretations_of_pathogenicity|_risk_factor','Conflicting_interpretations_of_pathogenicity|_protective','Conflicting_interpretations_of_pathogenicity|_other|_risk_factor','Conflicting_interpretations_of_pathogenicity|_other','Conflicting_interpretations_of_pathogenicity|_drug_response|_other','Conflicting_interpretations_of_pathogenicity|_drug_response','Conflicting_interpretations_of_pathogenicity|_association|_risk_factor','Conflicting_interpretations_of_pathogenicity|_association','Conflicting_interpretations_of_pathogenicity','confers_sensitivity','association|_risk_factor','association_not_found','association','Affects|_risk_factor','Affects|_association','Affects'], 'others')\n",
    "\n",
    "# only keep benign & pathogenic\n",
    "df_1 = df_1.loc[df_1['CLNSIG'].isin(['benign','pathogenic'])]\n",
    "\n",
    "# label encoder\n",
    "map_clnsig={'pathogenic':1,'benign':0}\n",
    "df_1['CLNSIG']=df_1['CLNSIG'].map(lambda s: map_clnsig.get(s) if s in map_clnsig else s)\n",
    "# df_1[\"CLNSIG\"].unique()\n",
    "\n",
    "\n",
    "\"\"\"4.2  keep imbalance classes \"\"\"\n",
    "\n",
    "# split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = df_1.iloc[:, 1:], df_1.iloc[:, 0]\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "    train_test_split(X, y, \n",
    "                    test_size=0.3,\n",
    "                    random_state=42,\n",
    "                    stratify=y)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" 5. features engineering: transformer\"\"\"\n",
    "## only for training data, no care about target 'CLNSIG', total 29 features\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import MissingIndicator, SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from category_encoders import BinaryEncoder                     # # pip install category_encoders\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "\n",
    "## numerical feature group 1 : replace missing with mean;  scaling/standardization\n",
    "\n",
    "numeric_feature_1 = ['MES-SWA_acceptor_alt','MES-SWA_acceptor_diff','MES-SWA_donor_alt','MES-SWA_donor_diff','MaxEntScan_alt','MaxEntScan_diff','GERP++_RS',\n",
    "    'phastCons100way_vertebrate','phyloP100way_vertebrate']\n",
    "\n",
    "\n",
    "\n",
    "## numerical feature group 2 : replace missing with 0;  scaling/standardization\n",
    "numeric_feature_2 = ['CADD','AF_TGP', 'Frq', 'GNOMADAF_popmax', 'Hom',\n",
    "       'SWEGENAF','LoFtool','pLI_gene_value','SpliceAI_pred_DS_AL',\n",
    "       'SpliceAI_pred_DS_DG','SpliceAI_pred_DS_DL']\n",
    "\n",
    "\n",
    "\n",
    "## numerical feature group 3: add missing indicator; replace missing with 0 and ; scaling/standardization\n",
    "numeric_feature_3 = ['SPIDEX','REVEL_score','SpliceAI_pred_DS_AG']\n",
    "\n",
    "\n",
    "\n",
    "## categorical ordinal feature group 4: add missing indicator for ['SIFT','PolyPhen']; replace missing with 'missing_value' string; OrdinalEncoder\n",
    "categori_oridinal_feature_4 =['Consequence','IMPACT','SIFT','PolyPhen']\n",
    "\n",
    "# ordinal features' order: left to right will be from 0 to length-1\n",
    "with open('variant_consequences.txt','r') as f:             # get the 'variant_consequences order' lst: descending severity\n",
    "    order_conseq=[line.rstrip(\"\\n\") for line in f] \n",
    "    order_conseq.reverse()\n",
    "\n",
    "ordinal_features = [\n",
    "    'Consequence',\n",
    "    'IMPACT',\n",
    "    'SIFT',\n",
    "    'PolyPhen']\n",
    "# 0 is the missing value will be replaced by\n",
    "ordinal_ordering = [\n",
    "    order_conseq,\n",
    "    ['MODIFIER','LOW','MODERATE','HIGH'],\n",
    "    ['tolerated_low_confidence','tolerated','deleterious_low_confidence','deleterious'],\n",
    "    ['unknown','benign','possibly_damaging','probably_damaging']\n",
    "    ]\n",
    "\n",
    "\n",
    "## categorical nominal feature group 5: replace missing with 0 in ['ORIGIN'], with ''missing_value' in ['BIOTYPE'];  BinaryEncoder\n",
    "categori_nominal_feature_5 = ['ORIGIN','BIOTYPE']  #,'BIOTYPE'\n",
    "\n",
    "\n",
    "\n",
    "numeric_feature_1_transformer =make_pipeline(\n",
    "    SimpleImputer(strategy='mean'),\n",
    "    StandardScaler()\n",
    ")\n",
    "\n",
    "numeric_feature_2_transformer =make_pipeline(\n",
    "    SimpleImputer(strategy='constant',fill_value=0),\n",
    "    StandardScaler()\n",
    ")\n",
    "\n",
    "numeric_feature_3_transformer =make_pipeline(\n",
    "    SimpleImputer(strategy='constant',fill_value=0),\n",
    "    StandardScaler()\n",
    ")\n",
    "\n",
    "categori_oridinal_feature_4_transformer =make_pipeline(\n",
    "    SimpleImputer(strategy='constant',fill_value=None),  # If None, fill_value will be 0 when imputing numerical data and “missing_value” for strings\n",
    "    OrdinalEncoder(categories=ordinal_ordering, handle_unknown='use_encoded_value', unknown_value = -1)       # the unknown 'missing_value' string will be enocoded as '-1'\n",
    ")\n",
    "\n",
    "categori_oridinal_feature_5_transformer =make_pipeline(\n",
    "    SimpleImputer(strategy='constant',fill_value=None),  \n",
    "    BinaryEncoder()                                # add new columns, throw the original columns automaticly, \n",
    ")\n",
    "\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_feature_1_transformer, numeric_feature_1),\n",
    "    (numeric_feature_2_transformer, numeric_feature_2 ),\n",
    "    (MissingIndicator(), numeric_feature_3 + categori_oridinal_feature_4[2:]),   # add new missing indicators for feature3 + ['SIFT','PolyPhen'] without originial columns,  here: total add 5 indicator columns\n",
    "    (numeric_feature_3_transformer, numeric_feature_3),  \n",
    "    (categori_oridinal_feature_4_transformer, categori_oridinal_feature_4),\n",
    "    (categori_oridinal_feature_5_transformer, categori_nominal_feature_5),                                                    \n",
    "    # (categori_oridinal_feature_5_transformer, categori_nominal_feature_5[1:])   # for checking: how many ori and biotype derived features seperately; must use [1:] formate, and see the `'BIOTYPE` first, and then can get `origin`\n",
    "    # remainder='passthrough'                                                   # so here for `BIOTYPE` derived new: 5   ,  `Origin` new: 6 \n",
    ")\n",
    "\n",
    "## total features after preprocessor: 43\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  train models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LG\n",
    "also for select feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=2000, C=10, random_state= 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.96125771, -2.57388812,  0.15075876, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.91355856,  0.13945432, -0.83543099, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.77713174, -0.08078451, -0.20987442, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       ...,\n",
       "       [-0.62446176,  0.79629462,  1.32337608, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.76755923, -0.07655593, -0.82544688, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.39739201, -0.65270072, -0.01174135, ...,  0.        ,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_proce = preprocessor.transform(X)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SFS\n",
    "SequentialFeatureSelector: The popular forward and backward feature selection approaches  \n",
    "\n",
    "http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  43 | elapsed:    4.2s remaining:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  43 | elapsed:    5.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  43 | elapsed:    5.7s finished\n",
      "\n",
      "[2023-04-28 18:49:05] Features: 1/43 -- score: 0.9492130006625765[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  42 | elapsed:    2.4s remaining:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of  42 | elapsed:    4.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of  42 | elapsed:    4.9s finished\n",
      "\n",
      "[2023-04-28 18:49:11] Features: 2/43 -- score: 0.9634571323079413[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  41 | elapsed:    3.3s remaining:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  41 | elapsed:    5.6s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  41 | elapsed:    6.5s finished\n",
      "\n",
      "[2023-04-28 18:49:17] Features: 3/43 -- score: 0.9681432176943348[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  40 | elapsed:    7.2s remaining:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  40 | elapsed:   12.1s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   14.2s finished\n",
      "\n",
      "[2023-04-28 18:49:31] Features: 4/43 -- score: 0.9711994153141169[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  39 | elapsed:    9.5s remaining:   21.3s\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  39 | elapsed:   16.4s remaining:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of  39 | elapsed:   20.7s finished\n",
      "\n",
      "[2023-04-28 18:49:52] Features: 5/43 -- score: 0.9731643847394962[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  38 | elapsed:   11.6s remaining:   28.6s\n",
      "[Parallel(n_jobs=-1)]: Done  31 out of  38 | elapsed:   20.9s remaining:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  38 | elapsed:   22.7s finished\n",
      "\n",
      "[2023-04-28 18:50:15] Features: 6/43 -- score: 0.9762648384274175[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  37 | elapsed:   17.2s remaining:   53.5s\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  37 | elapsed:   29.9s remaining:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done  37 out of  37 | elapsed:   32.1s finished\n",
      "\n",
      "[2023-04-28 18:50:47] Features: 7/43 -- score: 0.9778289743213648[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  36 | elapsed:   17.8s remaining:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  36 | elapsed:   31.2s remaining:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:   36.7s finished\n",
      "\n",
      "[2023-04-28 18:51:24] Features: 8/43 -- score: 0.9791111358383111[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  35 | elapsed:   31.0s remaining:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  35 | elapsed:   47.2s remaining:   21.7s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:  1.2min finished\n",
      "\n",
      "[2023-04-28 18:52:35] Features: 9/43 -- score: 0.9797724479422192[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  34 | elapsed:   40.0s remaining:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  34 | elapsed:   55.3s remaining:   26.4s\n",
      "[Parallel(n_jobs=-1)]: Done  34 out of  34 | elapsed:  1.4min finished\n",
      "\n",
      "[2023-04-28 18:54:02] Features: 10/43 -- score: 0.9800708602873862[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  33 | elapsed:   59.9s remaining: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  33 | elapsed:  1.2min remaining:   46.9s\n",
      "[Parallel(n_jobs=-1)]: Done  33 out of  33 | elapsed:  2.3min finished\n",
      "\n",
      "[2023-04-28 18:56:18] Features: 11/43 -- score: 0.9803857106007192[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  32 | elapsed:   48.3s remaining: 12.1min\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  32 | elapsed:   58.5s remaining:   40.0s\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed:  1.7min finished\n",
      "\n",
      "[2023-04-28 18:58:02] Features: 12/43 -- score: 0.9805829662187109[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  31 | elapsed:  1.4min remaining:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  31 out of  31 | elapsed:  2.4min finished\n",
      "\n",
      "[2023-04-28 19:00:26] Features: 13/43 -- score: 0.9806992964549626[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  30 | elapsed:  1.8min remaining:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  3.6min finished\n",
      "\n",
      "[2023-04-28 19:04:02] Features: 14/43 -- score: 0.9808181556093933[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  29 | elapsed:  1.9min remaining:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  29 | elapsed:  2.9min remaining:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  29 | elapsed:  3.3min finished\n",
      "\n",
      "[2023-04-28 19:07:20] Features: 15/43 -- score: 0.980885171941147[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  28 | elapsed:  1.5min remaining:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  26 out of  28 | elapsed:  2.5min remaining:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  28 | elapsed:  3.5min finished\n",
      "\n",
      "[2023-04-28 19:10:47] Features: 16/43 -- score: 0.9809281635501965[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  27 | elapsed:  2.3min remaining:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  27 | elapsed:  3.0min remaining:   41.0s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:  3.7min finished\n",
      "\n",
      "[2023-04-28 19:14:28] Features: 17/43 -- score: 0.9809635684047078[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  26 | elapsed:  2.5min remaining:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  26 | elapsed:  3.7min remaining:   52.8s\n",
      "[Parallel(n_jobs=-1)]: Done  26 out of  26 | elapsed:  4.9min finished\n",
      "\n",
      "[2023-04-28 19:19:19] Features: 18/43 -- score: 0.981011617850116[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  25 | elapsed:  2.5min remaining: 13.4min\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  25 | elapsed:  3.2min remaining:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  4.8min finished\n",
      "\n",
      "[2023-04-28 19:24:06] Features: 19/43 -- score: 0.9810331136546409[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  24 | elapsed:  1.9min remaining: 13.4min\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  24 | elapsed:  2.6min remaining:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  3.9min finished\n",
      "\n",
      "[2023-04-28 19:28:00] Features: 20/43 -- score: 0.9810356425728202[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  23 | elapsed:  3.0min remaining:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  23 | elapsed:  3.7min finished\n",
      "\n",
      "[2023-04-28 19:31:42] Features: 21/43 -- score: 0.981060931754614[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  22 | elapsed:  3.1min remaining:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  22 | elapsed:  3.7min finished\n",
      "\n",
      "[2023-04-28 19:35:24] Features: 22/43 -- score: 0.981060931754614[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  21 | elapsed:  3.5min remaining:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  20 | elapsed:  2.8min remaining:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  20 | elapsed:  3.5min remaining:   37.2s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  4.4min finished\n",
      "\n",
      "[2023-04-28 19:44:20] Features: 24/43 -- score: 0.9810672540500625[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  19 | elapsed:  3.0min remaining: 25.2min\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  19 | elapsed:  3.9min remaining:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:  4.7min finished\n",
      "\n",
      "[2023-04-28 19:48:59] Features: 25/43 -- score: 0.9810849564773181[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  18 | elapsed:  3.9min remaining:  2.5min\n",
      "/root/miniconda3/envs/myconda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:  4.8min finished\n",
      "\n",
      "[2023-04-28 19:53:45] Features: 26/43 -- score: 0.9810976010682151[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  17 | elapsed:  4.3min remaining:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  17 | elapsed:  4.9min remaining:   39.3s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:  5.4min finished\n",
      "\n",
      "[2023-04-28 19:59:09] Features: 27/43 -- score: 0.9811545017272512[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  16 | elapsed:  3.1min remaining:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  16 | elapsed:  3.4min remaining:   29.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:  3.6min finished\n",
      "\n",
      "[2023-04-28 20:02:47] Features: 28/43 -- score: 0.981236691568081[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:  4.5min remaining:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  4.7min finished\n",
      "\n",
      "[2023-04-28 20:07:29] Features: 29/43 -- score: 0.9812480716998881[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  14 | elapsed:  4.2min remaining:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:  4.7min finished\n",
      "\n",
      "[2023-04-28 20:12:08] Features: 30/43 -- score: 0.9812632452089645[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  13 | elapsed:  4.3min remaining:  2.7min\n",
      "/root/miniconda3/envs/myconda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/root/miniconda3/envs/myconda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/root/miniconda3/envs/myconda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:  5.2min finished\n",
      "\n",
      "[2023-04-28 20:17:23] Features: 31/43 -- score: 0.9812834765543996[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:  3.2min remaining:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  3.9min finished\n",
      "\n",
      "[2023-04-28 20:21:15] Features: 32/43 -- score: 0.9812784187180408[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "/root/miniconda3/envs/myconda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  11 | elapsed:  4.1min remaining:  3.5min\n",
      "/root/miniconda3/envs/myconda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/root/miniconda3/envs/myconda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:  4.5min finished\n",
      "\n",
      "[2023-04-28 20:25:45] Features: 33/43 -- score: 0.9812619807498748[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:  4.1min remaining:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  4.5min finished\n",
      "\n",
      "[2023-04-28 20:30:17] Features: 34/43 -- score: 0.9812468072407985[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:  3.7min remaining: 12.8min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   9 | elapsed:  4.0min remaining:  1.1min\n",
      "/root/miniconda3/envs/myconda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/root/miniconda3/envs/myconda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/root/miniconda3/envs/myconda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:  5.0min finished\n",
      "\n",
      "[2023-04-28 20:35:18] Features: 35/43 -- score: 0.9812543939953366[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:  3.4min remaining:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  4.2min finished\n",
      "\n",
      "[2023-04-28 20:39:27] Features: 36/43 -- score: 0.9812569229135161[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   7 | elapsed:  3.6min remaining:  2.7min\n",
      "/root/miniconda3/envs/myconda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/root/miniconda3/envs/myconda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/root/miniconda3/envs/myconda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/root/miniconda3/envs/myconda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/root/miniconda3/envs/myconda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:  5.2min finished\n",
      "\n",
      "[2023-04-28 20:44:40] Features: 37/43 -- score: 0.9812784187180408[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:  3.7min remaining:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  4.0min finished\n",
      "\n",
      "[2023-04-28 20:48:41] Features: 38/43 -- score: 0.9812607162907852[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  3.9min remaining:  2.6min\n",
      "/root/miniconda3/envs/myconda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  5.1min finished\n",
      "\n",
      "[2023-04-28 20:53:44] Features: 39/43 -- score: 0.981253129536247[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:  3.1min remaining:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  3.4min finished\n",
      "\n",
      "[2023-04-28 20:57:09] Features: 40/43 -- score: 0.9812341626499017[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "/root/miniconda3/envs/myconda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/root/miniconda3/envs/myconda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  4.9min finished\n",
      "\n",
      "[2023-04-28 21:02:03] Features: 41/43 -- score: 0.9811861132044934[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  3.4min finished\n",
      "\n",
      "[2023-04-28 21:05:28] Features: 42/43 -- score: 0.9811241547090985[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "/root/miniconda3/envs/myconda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  3.8min finished\n",
      "\n",
      "[2023-04-28 21:09:13] Features: 43/43 -- score: 0.9811190968727398"
     ]
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "sfs2 = SFS(lr, \n",
    "           k_features=43, \n",
    "           forward=True, \n",
    "           floating=False, \n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=2,\n",
    "           n_jobs=-1)\n",
    "\n",
    "sfs2 = sfs2.fit(X_proce , y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col1 = numeric_feature_1 + numeric_feature_2\n",
    "\n",
    "col2 = ['miss_SPIDEX', 'miss_REVEL_score', 'miss_SpliceAI_pred_DS_AG', 'miss_SIFT', 'miss_PolyPhen']\n",
    "\n",
    "col3 = numeric_feature_3 + categori_oridinal_feature_4\n",
    "\n",
    "col4 = ['ORIGIN_0', 'ORIGIN_1', 'ORIGIN_2', 'ORIGIN_3', 'ORIGIN_4', 'ORIGIN_5', 'BIOTYPE_0','BIOTYPE_1','BIOTYPE_2','BIOTYPE_3','BIOTYPE_4']\n",
    "\n",
    "cols = col1 + col2 + col3 + col4     ## get all columns's names after preprocessing\n",
    "len(cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_idx</th>\n",
       "      <th>cv_scores</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>feature_names</th>\n",
       "      <th>ci_bound</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>std_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(9,)</td>\n",
       "      <td>[0.950453435029563, 0.9479725662955901]</td>\n",
       "      <td>0.949213</td>\n",
       "      <td>(9,)</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.00124</td>\n",
       "      <td>0.00124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(9, 12)</td>\n",
       "      <td>[0.9663578014596915, 0.960556463156191]</td>\n",
       "      <td>0.963457</td>\n",
       "      <td>(9, 12)</td>\n",
       "      <td>0.012481</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.002901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(9, 12, 28)</td>\n",
       "      <td>[0.9702472776195799, 0.9660391577690896]</td>\n",
       "      <td>0.968143</td>\n",
       "      <td>(9, 12, 28)</td>\n",
       "      <td>0.009053</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.002104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(9, 12, 22, 28)</td>\n",
       "      <td>[0.9733502602256806, 0.9690485704025532]</td>\n",
       "      <td>0.971199</td>\n",
       "      <td>(9, 12, 22, 28)</td>\n",
       "      <td>0.009254</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.002151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(9, 12, 22, 26, 28)</td>\n",
       "      <td>[0.9751028005239919, 0.9712259689550005]</td>\n",
       "      <td>0.973164</td>\n",
       "      <td>(9, 12, 22, 26, 28)</td>\n",
       "      <td>0.00834</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.001938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(9, 12, 21, 22, 26, 28)</td>\n",
       "      <td>[0.9776190741124762, 0.9749106027423589]</td>\n",
       "      <td>0.976265</td>\n",
       "      <td>(9, 12, 21, 22, 26, 28)</td>\n",
       "      <td>0.005827</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.001354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(9, 12, 19, 21, 22, 26, 28)</td>\n",
       "      <td>[0.979123780429208, 0.9765341682135216]</td>\n",
       "      <td>0.977829</td>\n",
       "      <td>(9, 12, 19, 21, 22, 26, 28)</td>\n",
       "      <td>0.005571</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.001295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(9, 12, 19, 21, 22, 26, 28, 35)</td>\n",
       "      <td>[0.9804211154552306, 0.9778011562213916]</td>\n",
       "      <td>0.979111</td>\n",
       "      <td>(9, 12, 19, 21, 22, 26, 28, 35)</td>\n",
       "      <td>0.005636</td>\n",
       "      <td>0.00131</td>\n",
       "      <td>0.00131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(9, 12, 19, 21, 22, 26, 28, 35, 37)</td>\n",
       "      <td>[0.9811089812000222, 0.9784359146844163]</td>\n",
       "      <td>0.979772</td>\n",
       "      <td>(9, 12, 19, 21, 22, 26, 28, 35, 37)</td>\n",
       "      <td>0.005751</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.001337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(9, 10, 12, 19, 21, 22, 26, 28, 35, 37)</td>\n",
       "      <td>[0.981220253599915, 0.9789214669748575]</td>\n",
       "      <td>0.980071</td>\n",
       "      <td>(9, 10, 12, 19, 21, 22, 26, 28, 35, 37)</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.001149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(5, 9, 10, 12, 19, 21, 22, 26, 28, 35, 37)</td>\n",
       "      <td>[0.9814883189269294, 0.979283102274509]</td>\n",
       "      <td>0.980386</td>\n",
       "      <td>(5, 9, 10, 12, 19, 21, 22, 26, 28, 35, 37)</td>\n",
       "      <td>0.004744</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.001103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(5, 9, 10, 12, 19, 21, 22, 26, 28, 35, 37, 41)</td>\n",
       "      <td>[0.9817285661539706, 0.9794373662834512]</td>\n",
       "      <td>0.980583</td>\n",
       "      <td>(5, 9, 10, 12, 19, 21, 22, 26, 28, 35, 37, 41)</td>\n",
       "      <td>0.004929</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.001146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(5, 9, 10, 11, 12, 19, 21, 22, 26, 28, 35, 37,...</td>\n",
       "      <td>[0.9819106482628861, 0.9794879446470389]</td>\n",
       "      <td>0.980699</td>\n",
       "      <td>(5, 9, 10, 11, 12, 19, 21, 22, 26, 28, 35, 37,...</td>\n",
       "      <td>0.005212</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.001211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(5, 9, 10, 11, 12, 19, 21, 22, 26, 27, 28, 35,...</td>\n",
       "      <td>[0.9820623833536489, 0.9795739278651379]</td>\n",
       "      <td>0.980818</td>\n",
       "      <td>(5, 9, 10, 11, 12, 19, 21, 22, 26, 27, 28, 35,...</td>\n",
       "      <td>0.005353</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>0.001244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(3, 5, 9, 10, 11, 12, 19, 21, 22, 26, 27, 28, ...</td>\n",
       "      <td>[0.9821180195535953, 0.9796523243286986]</td>\n",
       "      <td>0.980885</td>\n",
       "      <td>(3, 5, 9, 10, 11, 12, 19, 21, 22, 26, 27, 28, ...</td>\n",
       "      <td>0.005305</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.001233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(3, 5, 9, 10, 11, 12, 19, 21, 22, 26, 27, 28, ...</td>\n",
       "      <td>[0.9821711268353623, 0.9796852002650306]</td>\n",
       "      <td>0.980928</td>\n",
       "      <td>(3, 5, 9, 10, 11, 12, 19, 21, 22, 26, 27, 28, ...</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>0.001243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(3, 5, 9, 10, 11, 12, 19, 21, 22, 26, 27, 28, ...</td>\n",
       "      <td>[0.9821989449353355, 0.9797281918740801]</td>\n",
       "      <td>0.980964</td>\n",
       "      <td>(3, 5, 9, 10, 11, 12, 19, 21, 22, 26, 27, 28, ...</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.001235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(3, 4, 5, 9, 10, 11, 12, 19, 21, 22, 26, 27, 2...</td>\n",
       "      <td>[0.982254581135282, 0.9797686545649502]</td>\n",
       "      <td>0.981012</td>\n",
       "      <td>(3, 4, 5, 9, 10, 11, 12, 19, 21, 22, 26, 27, 2...</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>0.001243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 19, 21, 22, 26, 27...</td>\n",
       "      <td>[0.9822823992352552, 0.9797838280740265]</td>\n",
       "      <td>0.981033</td>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 19, 21, 22, 26, 27...</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.001249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 13, 19, 21, 22, 26...</td>\n",
       "      <td>[0.9822571100534613, 0.979814175092179]</td>\n",
       "      <td>0.981036</td>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 13, 19, 21, 22, 26...</td>\n",
       "      <td>0.005256</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.001221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 13, 19, 21, 22, 26...</td>\n",
       "      <td>[0.9822925149079726, 0.9798293486012554]</td>\n",
       "      <td>0.981061</td>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 13, 19, 21, 22, 26...</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>0.001232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 19, 21, 22...</td>\n",
       "      <td>[0.9822773413988963, 0.9798445221103317]</td>\n",
       "      <td>0.981061</td>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 19, 21, 22...</td>\n",
       "      <td>0.005234</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.001216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 19, 21, 22...</td>\n",
       "      <td>[0.9823178040897664, 0.979847051028511]</td>\n",
       "      <td>0.981082</td>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 19, 21, 22...</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.001235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 19, 21, 22...</td>\n",
       "      <td>[0.982254581135282, 0.9798799269648429]</td>\n",
       "      <td>0.981067</td>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 19, 21, 22...</td>\n",
       "      <td>0.005109</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.001187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 19, 21, 22...</td>\n",
       "      <td>[0.982274812480717, 0.9798951004739193]</td>\n",
       "      <td>0.981085</td>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 19, 21, 22...</td>\n",
       "      <td>0.00512</td>\n",
       "      <td>0.00119</td>\n",
       "      <td>0.00119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 19, 21, 22...</td>\n",
       "      <td>[0.9822849281534345, 0.9799102739829956]</td>\n",
       "      <td>0.981098</td>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 19, 21, 22...</td>\n",
       "      <td>0.005109</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.001187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 19, 20, 21...</td>\n",
       "      <td>[0.9822419365443851, 0.9800670669101171]</td>\n",
       "      <td>0.981155</td>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 19, 20, 21...</td>\n",
       "      <td>0.004679</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.001087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 19, 20...</td>\n",
       "      <td>[0.9824417210805562, 0.9800316620556059]</td>\n",
       "      <td>0.981237</td>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 19, 20...</td>\n",
       "      <td>0.005185</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.001205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 17, 19...</td>\n",
       "      <td>[0.98246701026235, 0.9800291331374265]</td>\n",
       "      <td>0.981248</td>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 17, 19...</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.001219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 17, 18...</td>\n",
       "      <td>[0.9825277042986551, 0.9799987861192739]</td>\n",
       "      <td>0.981263</td>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 17, 18...</td>\n",
       "      <td>0.005441</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>0.001264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 17, 18...</td>\n",
       "      <td>[0.9825504645622696, 0.9800164885465296]</td>\n",
       "      <td>0.981283</td>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 17, 18...</td>\n",
       "      <td>0.005451</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>0.001267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 17, 18...</td>\n",
       "      <td>[0.9825529934804489, 0.9800038439556327]</td>\n",
       "      <td>0.981278</td>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 17, 18...</td>\n",
       "      <td>0.005484</td>\n",
       "      <td>0.001275</td>\n",
       "      <td>0.001275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 17, 18...</td>\n",
       "      <td>[0.9825226464622964, 0.9800013150374532]</td>\n",
       "      <td>0.981262</td>\n",
       "      <td>(1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 17, 18...</td>\n",
       "      <td>0.005424</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.001261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 17,...</td>\n",
       "      <td>[0.9825428778077314, 0.9799507366738657]</td>\n",
       "      <td>0.981247</td>\n",
       "      <td>(1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 17,...</td>\n",
       "      <td>0.005577</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>0.001296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>(1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 15, 16,...</td>\n",
       "      <td>[0.982540348889552, 0.9799684391011213]</td>\n",
       "      <td>0.981254</td>\n",
       "      <td>(1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 15, 16,...</td>\n",
       "      <td>0.005533</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.001286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>(1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 15, 16,...</td>\n",
       "      <td>[0.9825175886259376, 0.9799962572010945]</td>\n",
       "      <td>0.981257</td>\n",
       "      <td>(1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 15, 16,...</td>\n",
       "      <td>0.005424</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.001261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 15, ...</td>\n",
       "      <td>[0.9825428778077314, 0.9800139596283501]</td>\n",
       "      <td>0.981278</td>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 15, ...</td>\n",
       "      <td>0.005441</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>0.001264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "      <td>[0.9825808115804221, 0.9799406210011481]</td>\n",
       "      <td>0.981261</td>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "      <td>0.00568</td>\n",
       "      <td>0.00132</td>\n",
       "      <td>0.00132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[0.9825757537440634, 0.9799305053284306]</td>\n",
       "      <td>0.981253</td>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>0.005691</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>0.001323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[0.9825226464622964, 0.9799456788375069]</td>\n",
       "      <td>0.981234</td>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>0.005544</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>0.001288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[0.9824214897351211, 0.9799507366738657]</td>\n",
       "      <td>0.981186</td>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.001235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[0.9823102173352284, 0.9799380920829688]</td>\n",
       "      <td>0.981124</td>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>0.005103</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.001186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[0.9822899859897933, 0.9799482077556863]</td>\n",
       "      <td>0.981119</td>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>0.005038</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>0.001171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          feature_idx  \\\n",
       "1                                                (9,)   \n",
       "2                                             (9, 12)   \n",
       "3                                         (9, 12, 28)   \n",
       "4                                     (9, 12, 22, 28)   \n",
       "5                                 (9, 12, 22, 26, 28)   \n",
       "6                             (9, 12, 21, 22, 26, 28)   \n",
       "7                         (9, 12, 19, 21, 22, 26, 28)   \n",
       "8                     (9, 12, 19, 21, 22, 26, 28, 35)   \n",
       "9                 (9, 12, 19, 21, 22, 26, 28, 35, 37)   \n",
       "10            (9, 10, 12, 19, 21, 22, 26, 28, 35, 37)   \n",
       "11         (5, 9, 10, 12, 19, 21, 22, 26, 28, 35, 37)   \n",
       "12     (5, 9, 10, 12, 19, 21, 22, 26, 28, 35, 37, 41)   \n",
       "13  (5, 9, 10, 11, 12, 19, 21, 22, 26, 28, 35, 37,...   \n",
       "14  (5, 9, 10, 11, 12, 19, 21, 22, 26, 27, 28, 35,...   \n",
       "15  (3, 5, 9, 10, 11, 12, 19, 21, 22, 26, 27, 28, ...   \n",
       "16  (3, 5, 9, 10, 11, 12, 19, 21, 22, 26, 27, 28, ...   \n",
       "17  (3, 5, 9, 10, 11, 12, 19, 21, 22, 26, 27, 28, ...   \n",
       "18  (3, 4, 5, 9, 10, 11, 12, 19, 21, 22, 26, 27, 2...   \n",
       "19  (1, 3, 4, 5, 9, 10, 11, 12, 19, 21, 22, 26, 27...   \n",
       "20  (1, 3, 4, 5, 9, 10, 11, 12, 13, 19, 21, 22, 26...   \n",
       "21  (1, 3, 4, 5, 9, 10, 11, 12, 13, 19, 21, 22, 26...   \n",
       "22  (1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 19, 21, 22...   \n",
       "23  (1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 19, 21, 22...   \n",
       "24  (1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 19, 21, 22...   \n",
       "25  (1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 19, 21, 22...   \n",
       "26  (1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 19, 21, 22...   \n",
       "27  (1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 19, 20, 21...   \n",
       "28  (1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 19, 20...   \n",
       "29  (1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 17, 19...   \n",
       "30  (1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 17, 18...   \n",
       "31  (1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 17, 18...   \n",
       "32  (1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 17, 18...   \n",
       "33  (1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 17, 18...   \n",
       "34  (1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 17,...   \n",
       "35  (1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 15, 16,...   \n",
       "36  (1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 15, 16,...   \n",
       "37  (0, 1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 15, ...   \n",
       "38  (0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 1...   \n",
       "39  (0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "40  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "41  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "42  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "43  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "\n",
       "                                   cv_scores avg_score  \\\n",
       "1    [0.950453435029563, 0.9479725662955901]  0.949213   \n",
       "2    [0.9663578014596915, 0.960556463156191]  0.963457   \n",
       "3   [0.9702472776195799, 0.9660391577690896]  0.968143   \n",
       "4   [0.9733502602256806, 0.9690485704025532]  0.971199   \n",
       "5   [0.9751028005239919, 0.9712259689550005]  0.973164   \n",
       "6   [0.9776190741124762, 0.9749106027423589]  0.976265   \n",
       "7    [0.979123780429208, 0.9765341682135216]  0.977829   \n",
       "8   [0.9804211154552306, 0.9778011562213916]  0.979111   \n",
       "9   [0.9811089812000222, 0.9784359146844163]  0.979772   \n",
       "10   [0.981220253599915, 0.9789214669748575]  0.980071   \n",
       "11   [0.9814883189269294, 0.979283102274509]  0.980386   \n",
       "12  [0.9817285661539706, 0.9794373662834512]  0.980583   \n",
       "13  [0.9819106482628861, 0.9794879446470389]  0.980699   \n",
       "14  [0.9820623833536489, 0.9795739278651379]  0.980818   \n",
       "15  [0.9821180195535953, 0.9796523243286986]  0.980885   \n",
       "16  [0.9821711268353623, 0.9796852002650306]  0.980928   \n",
       "17  [0.9821989449353355, 0.9797281918740801]  0.980964   \n",
       "18   [0.982254581135282, 0.9797686545649502]  0.981012   \n",
       "19  [0.9822823992352552, 0.9797838280740265]  0.981033   \n",
       "20   [0.9822571100534613, 0.979814175092179]  0.981036   \n",
       "21  [0.9822925149079726, 0.9798293486012554]  0.981061   \n",
       "22  [0.9822773413988963, 0.9798445221103317]  0.981061   \n",
       "23   [0.9823178040897664, 0.979847051028511]  0.981082   \n",
       "24   [0.982254581135282, 0.9798799269648429]  0.981067   \n",
       "25   [0.982274812480717, 0.9798951004739193]  0.981085   \n",
       "26  [0.9822849281534345, 0.9799102739829956]  0.981098   \n",
       "27  [0.9822419365443851, 0.9800670669101171]  0.981155   \n",
       "28  [0.9824417210805562, 0.9800316620556059]  0.981237   \n",
       "29    [0.98246701026235, 0.9800291331374265]  0.981248   \n",
       "30  [0.9825277042986551, 0.9799987861192739]  0.981263   \n",
       "31  [0.9825504645622696, 0.9800164885465296]  0.981283   \n",
       "32  [0.9825529934804489, 0.9800038439556327]  0.981278   \n",
       "33  [0.9825226464622964, 0.9800013150374532]  0.981262   \n",
       "34  [0.9825428778077314, 0.9799507366738657]  0.981247   \n",
       "35   [0.982540348889552, 0.9799684391011213]  0.981254   \n",
       "36  [0.9825175886259376, 0.9799962572010945]  0.981257   \n",
       "37  [0.9825428778077314, 0.9800139596283501]  0.981278   \n",
       "38  [0.9825808115804221, 0.9799406210011481]  0.981261   \n",
       "39  [0.9825757537440634, 0.9799305053284306]  0.981253   \n",
       "40  [0.9825226464622964, 0.9799456788375069]  0.981234   \n",
       "41  [0.9824214897351211, 0.9799507366738657]  0.981186   \n",
       "42  [0.9823102173352284, 0.9799380920829688]  0.981124   \n",
       "43  [0.9822899859897933, 0.9799482077556863]  0.981119   \n",
       "\n",
       "                                        feature_names  ci_bound   std_dev  \\\n",
       "1                                                (9,)  0.005337   0.00124   \n",
       "2                                             (9, 12)  0.012481  0.002901   \n",
       "3                                         (9, 12, 28)  0.009053  0.002104   \n",
       "4                                     (9, 12, 22, 28)  0.009254  0.002151   \n",
       "5                                 (9, 12, 22, 26, 28)   0.00834  0.001938   \n",
       "6                             (9, 12, 21, 22, 26, 28)  0.005827  0.001354   \n",
       "7                         (9, 12, 19, 21, 22, 26, 28)  0.005571  0.001295   \n",
       "8                     (9, 12, 19, 21, 22, 26, 28, 35)  0.005636   0.00131   \n",
       "9                 (9, 12, 19, 21, 22, 26, 28, 35, 37)  0.005751  0.001337   \n",
       "10            (9, 10, 12, 19, 21, 22, 26, 28, 35, 37)  0.004945  0.001149   \n",
       "11         (5, 9, 10, 12, 19, 21, 22, 26, 28, 35, 37)  0.004744  0.001103   \n",
       "12     (5, 9, 10, 12, 19, 21, 22, 26, 28, 35, 37, 41)  0.004929  0.001146   \n",
       "13  (5, 9, 10, 11, 12, 19, 21, 22, 26, 28, 35, 37,...  0.005212  0.001211   \n",
       "14  (5, 9, 10, 11, 12, 19, 21, 22, 26, 27, 28, 35,...  0.005353  0.001244   \n",
       "15  (3, 5, 9, 10, 11, 12, 19, 21, 22, 26, 27, 28, ...  0.005305  0.001233   \n",
       "16  (3, 5, 9, 10, 11, 12, 19, 21, 22, 26, 27, 28, ...  0.005348  0.001243   \n",
       "17  (3, 5, 9, 10, 11, 12, 19, 21, 22, 26, 27, 28, ...  0.005315  0.001235   \n",
       "18  (3, 4, 5, 9, 10, 11, 12, 19, 21, 22, 26, 27, 2...  0.005348  0.001243   \n",
       "19  (1, 3, 4, 5, 9, 10, 11, 12, 19, 21, 22, 26, 27...  0.005375  0.001249   \n",
       "20  (1, 3, 4, 5, 9, 10, 11, 12, 13, 19, 21, 22, 26...  0.005256  0.001221   \n",
       "21  (1, 3, 4, 5, 9, 10, 11, 12, 13, 19, 21, 22, 26...  0.005299  0.001232   \n",
       "22  (1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 19, 21, 22...  0.005234  0.001216   \n",
       "23  (1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 19, 21, 22...  0.005315  0.001235   \n",
       "24  (1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 19, 21, 22...  0.005109  0.001187   \n",
       "25  (1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 19, 21, 22...   0.00512   0.00119   \n",
       "26  (1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 19, 21, 22...  0.005109  0.001187   \n",
       "27  (1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 19, 20, 21...  0.004679  0.001087   \n",
       "28  (1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 19, 20...  0.005185  0.001205   \n",
       "29  (1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 17, 19...  0.005245  0.001219   \n",
       "30  (1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 17, 18...  0.005441  0.001264   \n",
       "31  (1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 17, 18...  0.005451  0.001267   \n",
       "32  (1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 17, 18...  0.005484  0.001275   \n",
       "33  (1, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 17, 18...  0.005424  0.001261   \n",
       "34  (1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 16, 17,...  0.005577  0.001296   \n",
       "35  (1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 15, 16,...  0.005533  0.001286   \n",
       "36  (1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 15, 16,...  0.005424  0.001261   \n",
       "37  (0, 1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 15, ...  0.005441  0.001264   \n",
       "38  (0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 1...   0.00568   0.00132   \n",
       "39  (0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14...  0.005691  0.001323   \n",
       "40  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  0.005544  0.001288   \n",
       "41  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  0.005315  0.001235   \n",
       "42  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  0.005103  0.001186   \n",
       "43  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  0.005038  0.001171   \n",
       "\n",
       "     std_err  \n",
       "1    0.00124  \n",
       "2   0.002901  \n",
       "3   0.002104  \n",
       "4   0.002151  \n",
       "5   0.001938  \n",
       "6   0.001354  \n",
       "7   0.001295  \n",
       "8    0.00131  \n",
       "9   0.001337  \n",
       "10  0.001149  \n",
       "11  0.001103  \n",
       "12  0.001146  \n",
       "13  0.001211  \n",
       "14  0.001244  \n",
       "15  0.001233  \n",
       "16  0.001243  \n",
       "17  0.001235  \n",
       "18  0.001243  \n",
       "19  0.001249  \n",
       "20  0.001221  \n",
       "21  0.001232  \n",
       "22  0.001216  \n",
       "23  0.001235  \n",
       "24  0.001187  \n",
       "25   0.00119  \n",
       "26  0.001187  \n",
       "27  0.001087  \n",
       "28  0.001205  \n",
       "29  0.001219  \n",
       "30  0.001264  \n",
       "31  0.001267  \n",
       "32  0.001275  \n",
       "33  0.001261  \n",
       "34  0.001296  \n",
       "35  0.001286  \n",
       "36  0.001261  \n",
       "37  0.001264  \n",
       "38   0.00132  \n",
       "39  0.001323  \n",
       "40  0.001288  \n",
       "41  0.001235  \n",
       "42  0.001186  \n",
       "43  0.001171  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sfs_ranf = pd.DataFrame.from_dict(sfs2.get_metric_dict()).T\n",
    "df_sfs_ranf.to_csv('sfs_LG.csv')\n",
    "df_sfs_ranf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['CADD',\n",
       "  'GNOMADAF_popmax',\n",
       "  'miss_REVEL_score',\n",
       "  'miss_SpliceAI_pred_DS_AG',\n",
       "  'REVEL_score',\n",
       "  'Consequence'],\n",
       " ['CADD',\n",
       "  'GNOMADAF_popmax',\n",
       "  'SpliceAI_pred_DS_DL',\n",
       "  'miss_REVEL_score',\n",
       "  'miss_SpliceAI_pred_DS_AG',\n",
       "  'REVEL_score',\n",
       "  'Consequence',\n",
       "  'ORIGIN_3',\n",
       "  'ORIGIN_5'],\n",
       " ['CADD',\n",
       "  'AF_TGP',\n",
       "  'GNOMADAF_popmax',\n",
       "  'SpliceAI_pred_DS_DL',\n",
       "  'miss_REVEL_score',\n",
       "  'miss_SpliceAI_pred_DS_AG',\n",
       "  'REVEL_score',\n",
       "  'Consequence',\n",
       "  'ORIGIN_3',\n",
       "  'ORIGIN_5'],\n",
       " ['MaxEntScan_diff',\n",
       "  'CADD',\n",
       "  'AF_TGP',\n",
       "  'GNOMADAF_popmax',\n",
       "  'SpliceAI_pred_DS_DL',\n",
       "  'miss_REVEL_score',\n",
       "  'miss_SpliceAI_pred_DS_AG',\n",
       "  'REVEL_score',\n",
       "  'Consequence',\n",
       "  'ORIGIN_3',\n",
       "  'ORIGIN_5',\n",
       "  'BIOTYPE_3']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get the features name with index     in dic\n",
    "feature_names = cols\n",
    "dic_f=dict(enumerate(feature_names))\n",
    "\n",
    "### get the feature subsets 7-11 with higher accuracy, names and indice\n",
    "subsets2 = [6,9,10,12]  ## give how many features the subset includes\n",
    "feature_selection2= [[] for i in range(4)]     # initialize a nested list  https://www.freecodecamp.org/news/list-within-a-list-in-python-initialize-a-nested-list/\n",
    "a=0\n",
    "\n",
    "for i in subsets2:\n",
    "    \n",
    "    for j in (sfs2.subsets_[i]['feature_idx']):\n",
    "        feature_selection2[a].append(dic_f[j])\n",
    "\n",
    "    a+=1\n",
    "\n",
    "feature_selection2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 12, 19, 21, 22, 26, 28, 35, 37)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs2.subsets_[9]['feature_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "\n",
    "fig2 = plot_sfs(sfs2.get_metric_dict(), kind='std_dev')\n",
    "\n",
    "plt.ylim([0.945, 0.99])\n",
    "plt.title('Sequential Forward Selection',pad=20)\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid()\n",
    "plt.savefig('sfs_rf2_zoom.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig2 = plot_sfs(sfs2.get_metric_dict(), kind='std_dev')\n",
    "\n",
    "plt.ylim([0.978, 0.983])\n",
    "plt.title('Sequential Forward Selection')\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid()\n",
    "plt.savefig('sfs_rf1.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c02203d1d64a20e095821dadd6770e07e454ea747f2e6a086ab8a4b96e3b68a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
